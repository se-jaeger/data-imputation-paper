{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jenga.tasks.openml import OpenMLTask\n",
    "from jenga.corruptions.generic import MissingValues\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from data_imputation_paper.imputation.simple import ModeImputer\n",
    "from data_imputation_paper.imputation.ml import KNNImputer, ForestImputer\n",
    "from data_imputation_paper.imputation.generative import GAINImputer\n",
    "from data_imputation_paper.evaluation import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create example tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 categorical columns: ['V1', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15']\n",
      "Found 2 numeric columns: ['V2', 'V16']\n"
     ]
    }
   ],
   "source": [
    "task = OpenMLTask(seed=seed, openml_id=4552)\n",
    "\n",
    "if task.contains_missing_values():\n",
    "    raise ValueError(\"This would distort the evaluation because we wouldn't have a full ground truth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert missing values using jenga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = [\n",
    "    MissingValues(column='V2', fraction=0.5, na_value=np.nan, missingness='MCAR'),\n",
    "    MissingValues(column='V4', fraction=0.5, na_value=np.nan, missingness='MCAR'),\n",
    "    MissingValues(column='V15', fraction=0.5, na_value=np.nan, missingness='MCAR')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result contains 3 target columns: V2, V4, V15\n",
      "All are in a round-robin fashion imputed and performances are as follows:\n",
      "\n",
      "Target Column: V2\n",
      "            train         test\n",
      "MAE     29.954967    29.193205\n",
      "MSE   1411.781041  1396.991674\n",
      "RMSE    37.573675    37.376352\n",
      "\n",
      "Target Column: V4\n",
      "                train      test\n",
      "F1_micro     0.823036  0.844523\n",
      "F1_macro     0.451465  0.457854\n",
      "F1_weighted  0.743143  0.773337\n",
      "\n",
      "Target Column: V15\n",
      "                train      test\n",
      "F1_micro     0.124007  0.088339\n",
      "F1_macro     0.013791  0.010823\n",
      "F1_weighted  0.027362  0.014341\n",
      "\n",
      "CPU times: user 2.22 s, sys: 26.4 ms, total: 2.25 s\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "arguments = {\n",
    "    \"seed\": seed\n",
    "}\n",
    "\n",
    "%time Evaluator(task, missing_values, ModeImputer, arguments).evaluate(10).report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result contains 3 target columns: V2, V4, V15\n",
      "All are in a round-robin fashion imputed and performances are as follows:\n",
      "\n",
      "Target Column: V2\n",
      "            train         test\n",
      "MAE     30.697087    29.970671\n",
      "MSE   1479.275375  1390.832155\n",
      "RMSE    38.461349    37.293862\n",
      "\n",
      "Target Column: V4\n",
      "                train      test\n",
      "F1_micro     0.932921  0.957597\n",
      "F1_macro     0.880103  0.918508\n",
      "F1_weighted  0.931517  0.957398\n",
      "\n",
      "Target Column: V15\n",
      "                train      test\n",
      "F1_micro     0.501765  0.549470\n",
      "F1_macro     0.397952  0.412726\n",
      "F1_weighted  0.494373  0.540974\n",
      "\n",
      "CPU times: user 11.3 s, sys: 2.76 s, total: 14.1 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "arguments = {\n",
    "    \"seed\": seed,\n",
    "    \"hyperparameter_grid_categorical_imputer\": {\n",
    "        \"n_neighbors\": [3, 5]\n",
    "    },\n",
    "    \"hyperparameter_grid_numerical_imputer\": {\n",
    "        \"n_neighbors\": [3, 5]\n",
    "    }\n",
    "}\n",
    "\n",
    "%time Evaluator(task, missing_values, KNNImputer, arguments).evaluate(5).report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result contains 3 target columns: V2, V4, V15\n",
      "All are in a round-robin fashion imputed and performances are as follows:\n",
      "\n",
      "Target Column: V2\n",
      "            train         test\n",
      "MAE     28.146965    28.328991\n",
      "MSE   1258.807218  1318.998384\n",
      "RMSE    35.478678    36.316192\n",
      "\n",
      "Target Column: V4\n",
      "                train      test\n",
      "F1_micro     0.955958  0.951237\n",
      "F1_macro     0.919897  0.900870\n",
      "F1_weighted  0.955054  0.950382\n",
      "\n",
      "Target Column: V15\n",
      "                train      test\n",
      "F1_micro     0.550927  0.553004\n",
      "F1_macro     0.463676  0.420468\n",
      "F1_weighted  0.546331  0.552162\n",
      "\n",
      "CPU times: user 36.4 s, sys: 1.27 s, total: 37.7 s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "arguments = {\n",
    "    \"seed\": seed,\n",
    "    \"hyperparameter_grid_categorical_imputer\": {\n",
    "        \"n_estimators\": [50, 100]\n",
    "    },\n",
    "    \"hyperparameter_grid_numerical_imputer\": {\n",
    "        \"n_estimators\": [50, 100]\n",
    "    }\n",
    "}\n",
    "\n",
    "%time Evaluator(task, missing_values, ForestImputer, arguments).evaluate(5).report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAIN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: .model/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/code/data_imputation/data-imputation-paper/src/data_imputation_paper/evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, num_repetitions)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imputer_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imputer_arguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mtrain_imputed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_imputed_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/data_imputation/data-imputation-paper/src/data_imputation_paper/imputation/generative.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, target_columns)\u001b[0m\n\u001b[1;32m    320\u001b[0m         )  # NOTE: n_jobs=-1 causes troubles because TensorFlow shares the graph across processes\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/data-imputation-paper/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/data-imputation-paper/lib/python3.8/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: .model/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "arguments = {\n",
    "    \"num_data_columns\": task.train_data.shape[1],\n",
    "    \"seed\": seed,\n",
    "    \"hyperparameter_grid\": {\n",
    "        \"gain\": {\n",
    "            \"alpha\": [80, 120],\n",
    "            \"hint_rate\": [0.5, 0.9],\n",
    "            \"noise\": [0.001, 0.1]\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"batch_size\": [64, 256],\n",
    "            \"epochs\": [5, 15]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "%time Evaluator(task, missing_values, GAINImputer, arguments).evaluate(2).report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
