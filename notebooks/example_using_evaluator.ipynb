{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jenga.tasks.openml import OpenMLTask\n",
    "from jenga.corruptions.generic import MissingValues\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from data_imputation_paper.imputation.simple import ModeImputer\n",
    "from data_imputation_paper.imputation.ml import KNNImputer, ForestImputer\n",
    "from data_imputation_paper.evaluation import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create example tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 categorical columns: ['V1', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15']\n",
      "Found 2 numeric columns: ['V2', 'V16']\n"
     ]
    }
   ],
   "source": [
    "task = OpenMLTask(seed=42, openml_id=4552)\n",
    "\n",
    "if task.contains_missing_values():\n",
    "    raise ValueError(\"This would distort the evaluation because we wouldn't have a full ground truth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert missing values using jenga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = [\n",
    "    MissingValues(column='V2', fraction=0.5, na_value=np.nan, missingness='MCAR'),\n",
    "    MissingValues(column='V4', fraction=0.5, na_value=np.nan, missingness='MCAR'),\n",
    "    MissingValues(column='V15', fraction=0.5, na_value=np.nan, missingness='MCAR')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result contains 3 target columns: V2, V4, V15\n",
      "All are in a round-robin fashion imputed and performances are as follows:\n",
      "\n",
      "Target Column: V2\n",
      "           train        test\n",
      "MAE    16.887964   16.843340\n",
      "MSE   785.731773  779.331354\n",
      "RMSE   28.028850   27.910313\n",
      "\n",
      "Target Column: V4\n",
      "                train      test\n",
      "F1_micro     0.903796  0.900226\n",
      "F1_macro     0.772001  0.773260\n",
      "F1_weighted  0.887095  0.883218\n",
      "\n",
      "Target Column: V15\n",
      "                train      test\n",
      "F1_micro     0.496484  0.495812\n",
      "F1_macro     0.574888  0.572334\n",
      "F1_weighted  0.564149  0.566652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Evaluator(task, missing_values, ModeImputer(seed=seed)).evaluate(10).report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result contains 3 target columns: V2, V4, V15\n",
      "All are in a round-robin fashion imputed and performances are as follows:\n",
      "\n",
      "Target Column: V2\n",
      "            train         test\n",
      "MAE     30.327096    30.649187\n",
      "MSE   1450.408523  1457.419845\n",
      "RMSE    38.082157    38.161743\n",
      "\n",
      "Target Column: V4\n",
      "                train      test\n",
      "F1_micro     0.936275  0.949823\n",
      "F1_macro     0.877481  0.906966\n",
      "F1_weighted  0.934614  0.948433\n",
      "\n",
      "Target Column: V15\n",
      "                train      test\n",
      "F1_micro     0.506973  0.535336\n",
      "F1_macro     0.405233  0.441314\n",
      "F1_weighted  0.498939  0.529527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Evaluator(task, missing_values, KNNImputer(seed=seed)).evaluate(5).report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result contains 3 target columns: V2, V4, V15\n",
      "All are in a round-robin fashion imputed and performances are as follows:\n",
      "\n",
      "Target Column: V2\n",
      "            train         test\n",
      "MAE     27.750770    27.639080\n",
      "MSE   1231.435511  1226.041531\n",
      "RMSE    35.089002    35.009387\n",
      "\n",
      "Target Column: V4\n",
      "                train      test\n",
      "F1_micro     0.950132  0.964664\n",
      "F1_macro     0.903445  0.934303\n",
      "F1_weighted  0.949048  0.963818\n",
      "\n",
      "Target Column: V15\n",
      "                train      test\n",
      "F1_micro     0.550309  0.578445\n",
      "F1_macro     0.468850  0.491315\n",
      "F1_weighted  0.546476  0.572767\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Evaluator(task, missing_values, ForestImputer(seed=seed)).evaluate(5).report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
