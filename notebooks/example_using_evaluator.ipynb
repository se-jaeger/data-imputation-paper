{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jenga.tasks.openml import OpenMLTask\n",
    "from jenga.corruptions.generic import MissingValues\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from data_imputation_paper.imputation import SKLearnModeImputer, SKLearnIterativeImputer\n",
    "from data_imputation_paper.evaluation import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make determenistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create example tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 categorical columns: ['V1', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15']\n",
      "Found 2 numeric columns: ['V2', 'V16']\n"
     ]
    }
   ],
   "source": [
    "task = OpenMLTask(seed=42, openml_id=4552)\n",
    "\n",
    "if task.contains_missing_values():\n",
    "    raise ValueError(\"This would distort the evaluation because we wouln't have a full ground truth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert missing values using jenga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_missing = MissingValues(column='V2', fraction=0.5, na_value=np.nan, missingness='MCAR')\n",
    "categorical_missing = MissingValues(column='V3', fraction=0.5, na_value=np.nan, missingness='MCAR')\n",
    "categorical_as_string_missing = MissingValues(column='V4', fraction=0.5, na_value=np.nan, missingness='MCAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Evaluator\n",
    "\n",
    "Evaluators repeadetly:\n",
    "1. insert missing values into the dataset\n",
    "2. fit the imputer\n",
    "3. evauluate the train and test performance of the imputation\n",
    "\n",
    "Then it returns the mean evaluation result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples for mode imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_evaluator_numerical = Evaluator(task, numerical_missing, SKLearnModeImputer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 58.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>14.924881</td>\n",
       "      <td>14.531820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>712.367137</td>\n",
       "      <td>642.044099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>26.686727</td>\n",
       "      <td>25.333848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train        test\n",
       "MAE    14.924881   14.531820\n",
       "MSE   712.367137  642.044099\n",
       "RMSE   26.686727   25.333848"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_evaluator_numerical.evaluate(10).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_evaluator_categorical = Evaluator(task, categorical_missing, SKLearnModeImputer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1_micro</th>\n",
       "      <td>0.840666</td>\n",
       "      <td>0.840512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_macro</th>\n",
       "      <td>0.779786</td>\n",
       "      <td>0.776612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_weighted</th>\n",
       "      <td>0.822196</td>\n",
       "      <td>0.821427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                train      test\n",
       "F1_micro     0.840666  0.840512\n",
       "F1_macro     0.779786  0.776612\n",
       "F1_weighted  0.822196  0.821427"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_evaluator_categorical.evaluate(10).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_evaluator_cat_as_string = Evaluator(task, categorical_as_string_missing, SKLearnModeImputer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1_micro</th>\n",
       "      <td>0.914100</td>\n",
       "      <td>0.922154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_macro</th>\n",
       "      <td>0.807635</td>\n",
       "      <td>0.814039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_weighted</th>\n",
       "      <td>0.901798</td>\n",
       "      <td>0.911025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                train      test\n",
       "F1_micro     0.914100  0.922154\n",
       "F1_macro     0.807635  0.814039\n",
       "F1_weighted  0.901798  0.911025"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_evaluator_cat_as_string.evaluate(10).result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MICE imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_mice_numerical_ordinal = Evaluator(task, numerical_missing, SKLearnIterativeImputer(strategy=\"mice\", data_encoding_type=\"ordinal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>26.857458</td>\n",
       "      <td>25.954016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2153.424228</td>\n",
       "      <td>1972.734951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>46.403699</td>\n",
       "      <td>44.409269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train         test\n",
       "MAE     26.857458    25.954016\n",
       "MSE   2153.424228  1972.734951\n",
       "RMSE    46.403699    44.409269"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_mice_numerical_ordinal.evaluate(10).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_mice_numerical = Evaluator(task, numerical_missing, SKLearnIterativeImputer(strategy=\"mice\", data_encoding_type=\"one-hot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:33<00:00,  3.34s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>26.870653</td>\n",
       "      <td>26.220388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2159.661871</td>\n",
       "      <td>2013.499470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>46.470321</td>\n",
       "      <td>44.868159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train         test\n",
       "MAE     26.870653    26.220388\n",
       "MSE   2159.661871  2013.499470\n",
       "RMSE    46.470321    44.868159"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_mice_numerical.evaluate(10).result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## missForest imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_forest_numerical_ordinal = Evaluator(task, numerical_missing, SKLearnIterativeImputer(strategy=\"missforest\", data_encoding_type=\"ordinal\", estimator_args={\"n_estimators\": 20})) # we can feed arguments to estimators' constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:25<00:00,  2.55s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>26.944660</td>\n",
       "      <td>26.122771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2167.929656</td>\n",
       "      <td>2000.316593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>46.559215</td>\n",
       "      <td>44.714573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train         test\n",
       "MAE     26.944660    26.122771\n",
       "MSE   2167.929656  2000.316593\n",
       "RMSE    46.559215    44.714573"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_forest_numerical_ordinal.evaluate(10).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding is default\n",
    "evaluator_forest_numerical = Evaluator(task, numerical_missing, SKLearnIterativeImputer(strategy=\"missforest\", estimator_args={\"n_estimators\": 20})) # we can feed arguments to estimators' constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:31<01:05, 21.72s/it]"
     ]
    }
   ],
   "source": [
    "evaluator_forest_numerical.evaluate(10).result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values in Categorical Columns and `sklearn`s' `IterativImputer`\n",
    "\n",
    "Using `sklearn`s' `IterativImputer` can't be used for categorical columns at the moment.\n",
    "\n",
    "**There are two types of categorical values with different difficulties:**\n",
    "1. Strings: We need to encode these values to process them\n",
    "2. Numerical: Both estimators (`BayesianRidge` and `RandomForestRegressor`) will treat the imputation problem as regression instead of classification.\n",
    "\n",
    "**To 1.:** Using `OrdinalEncoder` to encode the column basically shifts this into a column of type 2. Using `OneHotEncoder` introduces the disadvantage that `sklearns` imputer can't find the missing values anymore because they only search for `np.nan` or any other given value (at learst as far as I know).\n",
    "\n",
    "**To 2.:** Could not find a solution yet ...\n",
    "\n",
    "\n",
    "With `sklearn` v0.24, which is not publsihed yet, we can use `OrdinalEncoder` with arguments `handle_unknown='use_encoded_value'` and `unknown_value=np.nan` to encode the categories and preserve the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_mice_categorical = Evaluator(task, categorical_missing, SKLearnIterativeImputer(strategy=\"mice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_mice_categorical.evaluate(10).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_mice_categorical_ordinal = Evaluator(task, categorical_missing, SKLearnIterativeImputer(strategy=\"mice\", data_encoding_type=\"ordinal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_mice_categorical_ordinal.evaluate(10).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_mice_cat_as_string = Evaluator(task, categorical_as_string_missing, SKLearnIterativeImputer(strategy=\"mice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_mice_cat_as_string.evaluate(10).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_forest_categorical = Evaluator(task, categorical_missing, SKLearnIterativeImputer(strategy=\"missforest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_forest_categorical.evaluate(10).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_forest_cat_as_string = Evaluator(task, categorical_as_string_missing, SKLearnIterativeImputer(strategy=\"missforest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_forest_cat_as_string.evaluate(10).result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
