{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jenga.tasks.openml import OpenMLTask\n",
    "from jenga.corruptions.generic import MissingValues\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from data_imputation_paper.imputation import SKLearnModeImputer\n",
    "from data_imputation_paper.evaluation import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make determenistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create example tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 categorical columns: ['RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2', 'ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY', 'ROLE_CODE']\n",
      "Found 0 numeric columns: []\n",
      "Found 0 categorical columns: []\n",
      "Found 14 numeric columns: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14']\n"
     ]
    }
   ],
   "source": [
    "categorical_task = OpenMLTask(seed=42, openml_id=4135)\n",
    "numerical_task = OpenMLTask(seed=42, openml_id=1471)\n",
    "\n",
    "if categorical_task.contains_missing_values() or numerical_task.contains_missing_values():\n",
    "    raise ValueError(\"This would distort the evaluation because we wouln't have a full ground truth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert missing values using jenga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1_missing = MissingValues(column='V1', fraction=0.5, na_value=np.nan, missingness='MCAR')\n",
    "role_family_missing = MissingValues(column='ROLE_FAMILY', fraction=0.5, na_value=np.nan, missingness='MCAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SKLearnModeImputer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Evaluator\n",
    "\n",
    "Evaluators repeadetly:\n",
    "1. insert missing values into the dataset\n",
    "2. fit the imputer\n",
    "3. evauluate the train and test performance of the imputation\n",
    "\n",
    "Then it returns the mean evaluation result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_numerical_task = Evaluator(numerical_task, V1_missing, imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 66.50it/s]\n"
     ]
    }
   ],
   "source": [
    "numerical_result = evaluator_numerical_task.evaluate(10, fit_kwargs={\"verbose\": 1}, transform_kwargs={})  # we can feed named arguments to the imputers fit and transform interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>3.269029e+01</td>\n",
       "      <td>20.454129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.880758e+06</td>\n",
       "      <td>3596.661244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.413556e+03</td>\n",
       "      <td>57.608630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train         test\n",
       "MAE   3.269029e+01    20.454129\n",
       "MSE   3.880758e+06  3596.661244\n",
       "RMSE  1.413556e+03    57.608630"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_result.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_categorical_task = Evaluator(categorical_task, role_family_missing, imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "categorical_result = evaluator_categorical_task.evaluate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F1_micro</th>\n",
       "      <td>0.668873</td>\n",
       "      <td>0.664434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_macro</th>\n",
       "      <td>0.650679</td>\n",
       "      <td>0.634385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_weighted</th>\n",
       "      <td>0.667989</td>\n",
       "      <td>0.664097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                train      test\n",
       "F1_micro     0.668873  0.664434\n",
       "F1_macro     0.650679  0.634385\n",
       "F1_weighted  0.667989  0.664097"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_result.result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
