%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Felix Bießmann at 2021-04-03 21:50:47 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@article{scikit-learn,
	author = {Pedregosa, F and Varoquaux, G and Gramfort, A and Michel, V and Thirion, B and Grisel, O and Blondel, M and Prettenhofer, P and Weiss, R and Dubourg, V and Vanderplas, J and Passos, A and Cournapeau, D and Brucher, M and Perrot, M and Duchesnay, E},
	date-added = {2021-04-03 21:50:39 +0200},
	date-modified = {2021-04-03 21:50:39 +0200},
	journal = {J. Mach. Learn. Res.},
	mendeley-groups = {Zotero - mendeley,Zotero - Zotero Library,Zotero - library},
	pages = {2825--2830},
	title = {{Scikit-learn: Machine Learning in {\{}P{\}}ython}},
	volume = {12},
	year = {2011}}

@article{OpenML2013,
	address = {New York, NY, USA},
	author = {Vanschoren, Joaquin and van Rijn, Jan N. and Bischl, Bernd and Torgo, Luis},
	date-added = {2021-04-03 21:35:15 +0200},
	date-modified = {2021-04-03 21:35:15 +0200},
	doi = {10.1145/2641190.2641198},
	journal = {SIGKDD Explorations},
	number = {2},
	pages = {49--60},
	publisher = {ACM},
	title = {OpenML: Networked Science in Machine Learning},
	url = {http://doi.acm.org/10.1145/2641190.2641198},
	volume = {15},
	year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2641190.2641198},
	Bdsk-Url-2 = {https://doi.org/10.1145/2641190.2641198}}

@book{vanBuuren2018,
	author = {S. van Buuren},
	date-added = {2021-04-02 21:09:34 +0200},
	date-modified = {2021-04-02 21:10:12 +0200},
	publisher = {CRC/Chapman \& Hall},
	title = {Flexible Imputation of Missing Data. 2nd ed},
	year = {2018}}

@article{Stekhoven2012,
	author = {Daniel J. Stekhoven and Peter B{\"{u}}hlmann},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/bioinformatics/StekhovenB12.bib},
	date-added = {2021-04-02 18:14:20 +0200},
	date-modified = {2021-04-02 18:14:33 +0200},
	doi = {10.1093/bioinformatics/btr597},
	journal = {Bioinform.},
	number = {1},
	pages = {112--118},
	timestamp = {Mon, 02 Mar 2020 00:00:00 +0100},
	title = {MissForest - non-parametric missing value imputation for mixed-type data},
	url = {https://doi.org/10.1093/bioinformatics/btr597},
	volume = {28},
	year = {2012},
	Bdsk-Url-1 = {https://dblp.org/rec/journals/bioinformatics/StekhovenB12},
	Bdsk-Url-2 = {https://doi.org/10.1093/bioinformatics/btr597}}

@article{Troyanskaya2001,
	author = {Olga G. Troyanskaya and Michael N. Cantor and Gavin Sherlock and Patrick O. Brown and Trevor Hastie and Robert Tibshirani and David Botstein and Russ B. Altman},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/bioinformatics/TroyanskayaCSBHTBA01.bib},
	date-added = {2021-04-02 18:11:51 +0200},
	date-modified = {2021-04-02 18:12:38 +0200},
	doi = {10.1093/bioinformatics/17.6.520},
	journal = {Bioinform.},
	number = {6},
	pages = {520--525},
	timestamp = {Mon, 02 Mar 2020 00:00:00 +0100},
	title = {Missing value estimation methods for {DNA} microarrays},
	url = {https://doi.org/10.1093/bioinformatics/17.6.520},
	volume = {17},
	year = {2001},
	Bdsk-Url-1 = {https://dblp.org/rec/journals/bioinformatics/TroyanskayaCSBHTBA01},
	Bdsk-Url-2 = {https://doi.org/10.1093/bioinformatics/17.6.520}}

@article{Mazumder2010,
	author = {Rahul Mazumder and Trevor Hastie and Robert Tibshirani},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/jmlr/MazumderHT10.bib},
	date-added = {2021-04-02 18:11:39 +0200},
	date-modified = {2021-04-02 18:13:15 +0200},
	journal = {J. Mach. Learn. Res.},
	pages = {2287--2322},
	timestamp = {Wed, 10 Jul 2019 01:00:00 +0200},
	title = {Spectral Regularization Algorithms for Learning Large Incomplete Matrices},
	url = {http://portal.acm.org/citation.cfm?id=1859931},
	volume = {11},
	year = {2010},
	Bdsk-Url-1 = {https://dblp.org/rec/journals/jmlr/MazumderHT10},
	Bdsk-Url-2 = {http://portal.acm.org/citation.cfm?id=1859931}}

@article{Koren2009,
	author = {Yehuda Koren and Robert M. Bell and Chris Volinsky},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/computer/KorenBV09.bib},
	date-added = {2021-04-02 18:11:17 +0200},
	date-modified = {2021-04-02 18:12:48 +0200},
	doi = {10.1109/MC.2009.263},
	journal = {Computer},
	number = {8},
	pages = {30--37},
	timestamp = {Wed, 12 Aug 2020 01:00:00 +0200},
	title = {Matrix Factorization Techniques for Recommender Systems},
	url = {https://doi.org/10.1109/MC.2009.263},
	volume = {42},
	year = {2009},
	Bdsk-Url-1 = {https://dblp.org/rec/journals/computer/KorenBV09},
	Bdsk-Url-2 = {https://doi.org/10.1109/MC.2009.263}}

@article{Batista2003,
	author = {Gustavo Batista and Maria Carolina Monard},
	date-added = {2021-04-02 18:04:41 +0200},
	date-modified = {2021-04-02 18:05:49 +0200},
	journal = {Applied Artificial Intelligence},
	number = {5-6},
	pages = {519--533},
	title = {An analysis of four missing data treatment methods for supervised learning},
	volume = {17},
	year = {2003}}

@article{Schelter2017,
	abstract = {We present a lightweight system to extract, store and manage metadata and prove-nance information of common artifacts in machine learning (ML) experiments: datasets, models, predictions, evaluations and training runs. Our system accelerates users in their ML workflow, and provides a basis for comparability and repeata-bility of ML experiments. We achieve this by tracking the lineage of produced artifacts and automatically extracting metadata such as hyperparameters of models, schemas of datasets or layouts of deep neural networks. Our system provides a general declarative representation of said ML artifacts, is integrated with popular frameworks such as MXNet, SparkML and scikit-learn, and meets the demands of various production use cases at Amazon.},
	author = {Schelter, Sebastian and B{\"{o}}se, Joos-Hendrik and Kirschnick, Johannes and Klein, Thoralf and Seufert, Stephan},
	date-added = {2021-04-02 17:46:25 +0200},
	date-modified = {2021-04-02 17:46:25 +0200},
	journal = {Mach. Learn. Syst. Work. NIPS},
	mendeley-groups = {Zotero - library,Zotero - Zotero Library},
	pages = {1--8},
	title = {{Automatically Tracking Metadata and Provenance of Machine Learning Experiments}},
	url = {http://learningsys.org/nips17/assets/papers/paper{\_}13.pdf},
	year = {2017},
	Bdsk-Url-1 = {http://learningsys.org/nips17/assets/papers/paper%7B%5C_%7D13.pdf}}

@article{biessmann2021automated,
	author = {Biessmann, Felix and Golebiowski, Jacek and Rukat, Tammo and Lange, Dustin and Schmidt, Philipp},
	date-added = {2021-04-02 17:42:35 +0200},
	date-modified = {2021-04-02 17:42:35 +0200},
	journal = {Bulletin of the IEEE Computer Society Technical Committee on Data Engineering},
	title = {Automated data validation in machine learning systems},
	year = {2021}}

@inproceedings{rukat2020towards,
	author = {Rukat, Tammo and Lange, Dustin and Schelter, Sebastian and Biessmann, Felix},
	booktitle = {ML Ops Work. Conf. Mach. Learn. Syst.},
	date-added = {2021-04-02 17:39:10 +0200},
	date-modified = {2021-04-02 17:39:10 +0200},
	mendeley-groups = {Zotero - library,Zotero - Zotero Library},
	pages = {1--3},
	title = {{Towards Automated Data Quality Management for Machine Learning}},
	year = {2020}}

@techreport{Abedjan2016,
	abstract = {Data cleaning has played a critical role in ensuring data quality for enterprise applications. Naturally, there has been extensive research in this area, and many data cleaning algorithms have been translated into tools to detect and to possibly repair certain classes of errors such as outliers, duplicates, missing values, and violations of integrity constraints. Since different types of errors may coexist in the same data set, we often need to run more than one kind of tool. In this paper, we investigate two pragmatic questions: (1) are these tools robust enough to capture most errors in real-world data sets? and (2) what is the best strategy to holistically run multiple tools to optimize the detection effort? To answer these two questions, we obtained multiple data cleaning tools that utilize a variety of error detection techniques. We also collected five real-world data sets, for which we could obtain both the raw data and the ground truth on existing errors. In this paper, we report our experimental findings on the errors detected by the tools we tested. First, we show that the coverage of each tool is well below 100{\%}. Second, we show that the order in which multiple tools are run makes a big difference. Hence, we propose a holistic multi-tool strategy that orders the invocations of the available tools to maximize their benefit, while minimizing human effort in verifying results. Third, since this holistic approach still does not lead to acceptable error coverage, we discuss two simple strategies that have the potential to improve the situation, namely domain specific tools and data enrichment. We close this paper by reasoning about the errors that are not detectable by any of the tools we tested.},
	author = {Abedjan, Ziawasch and Chu, Xu and Deng, Dong and Fernandez, Raul Castro and Ilyas, Ihab F. and Ouzzani, Mourad and Papotti, Paolo and Stonebraker, Michael and Tang, Nan},
	booktitle = {Proc. VLDB Endow.},
	date-added = {2021-04-02 17:37:14 +0200},
	date-modified = {2021-04-02 17:37:14 +0200},
	doi = {10.14778/2994509.2994518},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Abedjan et al/2016/Abedjan et al. - 2016 - Detecting data errors Where are we and what needs to be done.pdf:pdf},
	issn = {21508097},
	mendeley-groups = {dataset shift,imputation,Zotero - library,Zotero - Zotero Library},
	number = {12},
	pages = {993--1004},
	title = {{Detecting data errors: Where are we and what needs to be done?}},
	volume = {9},
	year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.14778/2994509.2994518}}

@inproceedings{Bender2021,
	abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
	author = {Bender, Emily M and Gebru, Timnit and Mcmillan-Major, Angelina and Shmitchell, Shmargaret and Shmitchell, Shmar-Garet},
	booktitle = {FaccT 2021},
	date-added = {2021-04-02 17:36:25 +0200},
	date-modified = {2021-04-02 17:36:25 +0200},
	doi = {10.1145/3442188.3445922},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Bender et al/2021/Bender et al. - 2021 - On the Dangers of Stochastic Parrots Can Language Models Be Too Big.pdf:pdf},
	isbn = {9781450383097},
	mendeley-groups = {interpretability,mlsys,Zotero - library,Zotero - Zotero Library},
	title = {{On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?}},
	url = {https://doi.org/10.1145/3442188.3445922},
	year = {2021},
	Bdsk-Url-1 = {https://doi.org/10.1145/3442188.3445922}}

@article{Schelter2018,
	abstract = {Modern companies and institutions rely on data to guide every single business process and decision. Missing or incorrect information seriously compromises any decision process downstream. Therefore, a crucial, but tedious task for everyone involved in data processing is to verify the quality of their data. We present a system for automating the verification of data quality at scale, which meets the requirements of production use cases. Our system provides a declarative API, which combines common quality constraints with userde fined validation code, and thereby enables 'unit tests' for data. We efficiently execute the resulting constraint validation workload by translating it to aggregation queries on Apache Spark. Our platform supports the incremental validation of data quality on growing datasets, and leverages machine learning, e.g., for enhancing constraint suggestions, for estimating the 'predictability' of a column, and for detecting anomalies in historic data quality time series. We discuss our design decisions, describe the resulting system architecture, and present an experimental evaluation on various datasets.},
	author = {Schelter, Sebastian and Lange, Dustin and Schmidt, Philipp and Celikel, Meltem and Biessmann, Felix and Grafberger, Andreas},
	date-added = {2021-04-02 17:33:14 +0200},
	date-modified = {2021-04-02 17:33:14 +0200},
	doi = {10.14778/3229863.3229867},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Schelter et al/2018/Schelter et al. - 2018 - Automating large-scale data quality verification.pdf:pdf},
	issn = {21508097},
	journal = {Proc. VLDB Endow.},
	mendeley-groups = {Ml Advances,mlsys,Zotero - Machine Learning,Zotero - Zotero Library,Zotero - mendeley,Zotero - library},
	number = {12},
	pages = {1781--1794},
	title = {{Automating large-scale data quality verification}},
	url = {https://doi.org/10.14778/3229863.3229867},
	volume = {11},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.14778/3229863.3229867}}

@misc{Ziemann2016,
	abstract = {The spreadsheet software Microsoft Excel, when used with default settings, is known to convert gene names to dates and floating-point numbers. A programmatic scan of leading genomics journals reveals that approximately one-fifth of papers with supplementary Excel gene lists contain erroneous gene name conversions.},
	author = {Ziemann, Mark and Eren, Yotam and El-Osta, Assam},
	booktitle = {Genome Biol.},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	doi = {10.1186/s13059-016-1044-7},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Ziemann, Eren, El-Osta/2016/Ziemann, Eren, El-Osta - 2016 - Gene name errors are widespread in the scientific literature.pdf:pdf},
	issn = {1474760X},
	keywords = {Gene symbol,Microsoft Excel,Supplementary data},
	mendeley-groups = {mlsys,Zotero - library,Zotero - Zotero Library},
	month = {aug},
	number = {1},
	pages = {177},
	pmid = {27552985},
	publisher = {BioMed Central Ltd.},
	title = {{Gene name errors are widespread in the scientific literature}},
	url = {http://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1044-7},
	volume = {17},
	year = {2016},
	Bdsk-Url-1 = {http://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1044-7},
	Bdsk-Url-2 = {https://doi.org/10.1186/s13059-016-1044-7}}

@inproceedings{Bose2017b,
	abstract = {We present a platform built on large-scale, data-centric machine learning (ML) approaches, whose particular focus is demand forecasting in retail. At its core, this platform enables the training and application of probabilistic demand forecasting models, and provides convenient abstractions and support functionality for forecasting problems. The platform comprises of a complex end-to-end machine learning system built on Apache Spark, which includes data preprocessing, feature engineering, distributed learning, as well as evaluation, experimentation and ensembling. Furthermore, it meets the demands of a production system and scales to large catalogues containing millions of items. We describe the challenges of building such a platform and discuss our design decisions. We detail aspects on several levels of the system, such as a set of general distributed learning schemes, our machinery for ensembling predictions, and a high-level data ow abstraction for modeling complex ML pipelines. To the best of our knowledge, we are not aware of prior work on real-world demand forecasting systems which rivals our approach in terms of scalability.},
	author = {B{\"{o}}se, Joos Hendrik and Flunkert, Valentin and Gasthaus, Jan and Januschowski, Tim and Lange, Dustin and Salinas, David and Schelter, Sebastian and Seeger, Matthias and Wang, Yuyang},
	booktitle = {Proc. VLDB Endow.},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	doi = {10.14778/3137765.3137775},
	issn = {21508097},
	mendeley-groups = {mlsys,Zotero - library,Zotero - Zotero Library},
	number = {12},
	pages = {1694--1705},
	title = {{Probabilistic demand forecasting at scale}},
	volume = {10},
	year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.14778/3137765.3137775}}

@article{Yang2020,
	abstract = {Surfacing and mitigating bias in ML pipelines is a complex topic, with a dire need to provide system-level support to data scientists. Humans should be empowered to debug these pipelines, in order to control for bias and to improve data quality and representativeness. We propose fair-DAGs, an open-source library that extracts directed acyclic graph (DAG) representations of the data flow in preprocessing pipelines for ML. The library subsequently instruments the pipelines with tracing and vi-sualization code to capture changes in data distributions and identify distortions with respect to protected group membership as the data travels through the pipeline. We illustrate the utility of fair-DAGs with experiments on publicly available ML pipelines.},
	author = {Yang, Ke and Huang, Biao and Schelter, Sebastian},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	doi = {10.1145/3398730.3399194},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Yang, Huang, Schelter/2020/Yang, Huang, Schelter - 2020 - Fairness-Aware Instrumentation of Preprocessing Pipelines for Machine Learning.pdf:pdf},
	isbn = {9781450380225},
	mendeley-groups = {mlsys,Zotero - library,Zotero - Zotero Library},
	title = {{Fairness-Aware Instrumentation of Preprocessing Pipelines for Machine Learning}},
	url = {https://doi.org/10.1145/3398730.3399194},
	year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1145/3398730.3399194}}

@article{Stoyanovich2020,
	abstract = {The need for responsible data management intensifies with the growing impact of data on society. One central locus of the societal impact of data are Automated Decision Systems (ADS), socio-legal-technical systems that are used broadly in industry, non-profits, and government. ADS process data about people, help make decisions that are consequential to people's lives, are designed with the stated goals of improving efficiency and promoting equitable access to opportunity, involve a combination of human and automated decision making, and are subject to auditing for legal compliance and to public disclosure. They may or may not use AI, and may or may not operate with a high degree of autonomy, but they rely heavily on data.In this article, we argue that the data management community is uniquely positioned to lead the responsible design, development, use, and oversight of ADS. We outline a technical research agenda that requires that we step outside our comfort zone of engineering for efficiency and accuracy, to also incorporate reasoning about values and beliefs. This seems high-risk, but one of the upsides is being able to explain to our children what we do and why it matters.},
	author = {Stoyanovich, Julia and Howe, Bill and Jagadish, H. V.},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	doi = {10.14778/3415478.3415570},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Stoyanovich, Howe, Jagadish/2020/Stoyanovich, Howe, Jagadish - 2020 - Responsible data management.pdf:pdf},
	issn = {2150-8097},
	journal = {Proc. VLDB Endow.},
	mendeley-groups = {mlsys,fairness,Zotero - library,Zotero - Zotero Library},
	number = {12},
	pages = {3474--3488},
	publisher = {PVLDB},
	title = {{Responsible data management}},
	url = {https://doi.org/10.14778/3415478.3415570},
	volume = {13},
	year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.14778/3415478.3415570}}

@article{Zhang2020,
	abstract = {This paper provides a comprehensive survey of Machine Learning Testing (ML testing) research. It covers 128 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing.},
	archiveprefix = {arXiv},
	arxivid = {1906.10742},
	author = {Zhang, Jie M. and Harman, Mark and Ma, Lei and Liu, Yang},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	doi = {10.1109/tse.2019.2962027},
	eprint = {1906.10742},
	issn = {23318422},
	journal = {arXiv},
	keywords = {Deep neural network,Machine learning,Software testing},
	mendeley-groups = {mlsys,Zotero - library,Zotero - Zotero Library},
	month = {feb},
	pages = {1--1},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	title = {{Machine learning testing: Survey, landscapes and horizons}},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1109/tse.2019.2962027}}

@article{Abedjan2018,
	abstract = {Data profiling comprises a broad range of methods to ef-ficiently analyze a given data set. In a typical scenario, which mirrors the capabilities of commercial data pro-filing tools, tables of a relational database are scanned to derive metadata, such as data types and value pat-terns, completeness and uniqueness of columns, keys and foreign keys, and occasionally functional dependen-cies and association rules. Individual research projects have proposed several additional profiling tasks, such as the discovery of inclusion dependencies or conditional functional dependencies. Data profiling deserves a fresh look for two reasons: First, the area itself is neither established nor defined in any principled way, despite significant research activity on individual parts in the past. Second, more and more data beyond the traditional relational databases are be-ing created and beg to be profiled. The article proposes new research directions and challenges, including inter-active and incremental profiling and profiling heteroge-neous and non-relational data.},
	author = {Abedjan, Ziawasch and Golab, Lukasz and Naumann, Felix and Papenbrock, Thorsten},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	doi = {10.2200/s00878ed1v01y201810dtm052},
	issn = {2153-5418},
	journal = {Synth. Lect. Data Manag.},
	mendeley-groups = {mlsys,Zotero - library,Zotero - Zotero Library},
	month = {nov},
	number = {4},
	pages = {1--154},
	publisher = {Morgan {\&} Claypool Publishers LLC},
	title = {{Data Profiling}},
	volume = {10},
	year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.2200/s00878ed1v01y201810dtm052}}

@techreport{Zaharia2018,
	abstract = {Machine learning development creates multiple new challenges that are not present in a traditional software development lifecycle. These include keeping track of the myriad inputs to an ML application (e.g., data versions, code and tuning parameters), reproducing results, and production deployment. In this paper, we summarize these challenges from our experience with Databricks customers, and describe MLflow, an open source platform we recently launched to streamline the machine learning lifecycle. MLflow covers three key challenges: experimentation, reproducibility, and model deployment, using generic APIs that work with any ML library, algorithm and programming language. The project has a rapidly growing open source community, with over 50 contributors since its launch in June 2018.},
	author = {Zaharia, Matei and Chen, Andrew and Davidson, Aaron and Ghodsi, Ali and Hong, Sue Ann and Konwinski, Andy and Murching, Siddharth and Nykodym, Tomas and Ogilvie, Paul and Parkhe, Mani and Xie, Fen and Zumar, Corey},
	booktitle = {Bull. IEEE Comput. Soc. Tech. Comm. Data Eng.},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Ovadia et al/2010/Ovadia et al. - 2010 - No Title.pdf:pdf},
	mendeley-groups = {mlsys},
	pages = {39--45},
	title = {{Accelerating the Machine Learning Lifecycle with MLflow}},
	year = {2018}}

@techreport{Breck2019,
	abstract = {Machine learning is a powerful tool for gleaning knowledge from massive amounts of data. While a great deal of machine learning research has focused on improving the accuracy and efficiency of training and inference algorithms, there is less attention in the equally important problem of monitoring the quality of data fed to machine learning. The importance of this problem is hard to dispute: errors in the input data can nullify any benefits on speed and accuracy for training and inference. This argument points to a data-centric approach to machine learning that treats training and serving data as an important production asset, on par with the algorithm and infrastructure used for learning. In this paper, we tackle this problem and present a data validation system that is designed to detect anomalies specifically in data fed into machine learning pipelines. This system is deployed in production as an integral part of TFX(Baylor et al., 2017)-an end-to-end machine learning platform at Google. It is used by hundreds of product teams use it to continuously monitor and validate several petabytes of production data per day. We faced several challenges in developing our system, most notably around the ability of ML pipelines to soldier on in the face of unexpected patterns, schema-free data, or training/serving skew. We discuss these challenges, the techniques we used to address them, and the various design choices that we made in implementing the system. Finally, we present evidence from the system's deployment in production that illustrate the tangible benefits of data validation in the context of ML: early detection of errors, model-quality wins from using better data, savings in engineering hours to debug problems, and a shift towards data-centric workflows in model development.},
	author = {Breck, Eric and Polyzotis, Neoklis and Roy, Sudip and Whang, Steven Euijong and Zinkevich, Martin},
	booktitle = {SysML},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Ovadia et al/2010/Ovadia et al. - 2010 - No Title.pdf:pdf},
	mendeley-groups = {mlsys,Zotero - library,Zotero - Zotero Library},
	pages = {1----14},
	title = {{Data Validation for Machine Learning}},
	year = {2019}}

@inproceedings{Baylor2017,
	abstract = {Creating and maintaining a platform for reliably producing and deploying machine learning models requires careful orchestration of many components - a learner for generating models based on training data, modules for analyzing and validating both data as well as models, and finally infrastructure for serving models in production. This becomes particularly challenging when data changes over time and fresh models need to be produced continuously. Unfortunately, such orchestration is often done ad hoc using glue code and custom scripts developed by individual teams for specific use cases, leading to duplicated effort and fragile systems with high technical debt. We present TensorFlow Extended (TFX), a TensorFlow-based general-purpose machine learning platform implemented at Google. By integrating the aforementioned components into one platform, we were able to standardize the components, simplify the platform configuration, and reduce the time to production from the order of months to weeks, while providing platform stability that minimizes disruptions. We present the case study of one deployment of TFX in the Google Play app store, where the machine learning models are refreshed continuously as new data arrive. Deploying TFX led to reduced custom code, faster experiment cycles, and a 2{\%} increase in app installs resulting from improved data and model analysis.},
	address = {New York, NY, USA},
	author = {Baylor, Denis and Breck, Eric and Cheng, Heng Tze and Fiedel, Noah and Foo, Chuan Yu and Haque, Zakaria and Haykal, Salem and Ispir, Mustafa and Jain, Vihan and Koc, Levent and Koo, Chiu Yuen and Lew, Lukasz and Mewald, Clemens and Modi, Akshay Naresh and Polyzotis, Neoklis and Ramesh, Sukriti and Roy, Sudip and Whang, Steven Euijong and Wicke, Martin and Wilkiewicz, Jarek and Zhang, Xin and Zinkevich, Martin},
	booktitle = {Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	doi = {10.1145/3097983.3098021},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Ovadia et al/2010/Ovadia et al. - 2010 - No Title.pdf:pdf},
	isbn = {9781450348874},
	keywords = {Continuous training,End-to-end platform,Large-scale machine learning},
	mendeley-groups = {mlsys},
	month = {aug},
	pages = {1387--1395},
	publisher = {Association for Computing Machinery},
	title = {{TFX: A TensorFlow-based production-scale machine learning platform}},
	url = {https://dl.acm.org/doi/10.1145/3097983.3098021},
	volume = {Part F1296},
	year = {2017},
	Bdsk-Url-1 = {https://dl.acm.org/doi/10.1145/3097983.3098021},
	Bdsk-Url-2 = {https://doi.org/10.1145/3097983.3098021}}

@article{Kumar,
	abstract = {Large-scale data analytics using statistical machine learning (ML), popularly called advanced analytics, underpins many modern data-driven applications. The data management community has been working for over a decade on tackling data management-related challenges that arise in ML workloads, and has built several systems for advanced analytics. This tutorial provides a comprehensive review of such systems and analyzes key data management challenges and techniques. We focus on three complementary lines of work: (1) integrating ML algorithms and languages with existing data systems such as RDBMSs, (2) adapting data management-inspired techniques such as query optimization, partitioning, and compression to new systems that target ML workloads, and (3) combining data management and ML ideas to build systems that improve ML lifecycle-related tasks. Finally, we identify key open data management challenges for future research in this important area.},
	author = {Kumar, Arun and Boehm, Matthias and Yang, Jun},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	doi = {10.1145/3035918.3054775},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Ovadia et al/2010/Ovadia et al. - 2010 - No Title.pdf:pdf},
	isbn = {9781450341974},
	issn = {07308078},
	journal = {Proc. ACM SIGMOD Int. Conf. Manag. Data},
	mendeley-groups = {mlsys,Zotero - library,Zotero - Zotero Library},
	pages = {1717--1722},
	title = {{Data management in machine learning: Challenges, techniques, and systems}},
	url = {http://dx.doi.org/10.1145/3035918.3054775},
	volume = {Part F1277},
	year = {2017},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/3035918.3054775}}

@techreport{Schelter2015,
	abstract = {The training, maintenance, deployment, monitoring, organization and documentation of machine learning (ML) models-in short model management-is a critical task in virtually all production ML use cases. Wrong model management decisions can lead to poor performance of a ML system and can result in high maintenance cost. As both research on infrastructure as well as on algorithms is quickly evolving, there is a lack of understanding of challenges and best practices for ML model management. Therefore, this field is receiving increased attention in recent years, both from the data management as well as from the ML community. In this paper, we discuss a selection of ML use cases, develop an overview over conceptual, engineering, and data-processing related challenges arising in the management of the corresponding ML models, and point out future research directions.},
	author = {Schelter, Sebastian and Biessmann, Felix and Januschowski, Tim and Salinas, David and Seufert, Stephan and Szarvas, Gyuri},
	booktitle = {Bull. IEEE Comput. Soc. Tech. Comm. Data Eng.},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Ovadia et al/2010/Ovadia et al. - 2010 - No Title.pdf:pdf},
	mendeley-groups = {mlsys,Zotero - Machine Learning,Zotero - Zotero Library,Zotero - mendeley,Zotero - library},
	pages = {5--13},
	title = {{On Challenges in Machine Learning Model Management}},
	url = {http://sites.computer.org/debull/A18dec/p5.pdf},
	year = {2018},
	Bdsk-Url-1 = {http://sites.computer.org/debull/A18dec/p5.pdf}}

@article{Heidari2019,
	abstract = {We introduce a few-shot learning framework for error detection. We show that data augmentation (a form of weak supervision) is key to training high-quality, ML-based error detection models that require minimal human involvement. Our framework consists of two parts: (1) an expressive model to learn rich representations that capture the inherent syntactic and semantic heterogeneity of errors; and (2) a data augmentation model that, given a small seed of clean records, uses dataset-specific transformations to automatically generate additional training data. Our key insight is to learn data augmentation policies from the noisy input dataset in a weakly supervised manner. We show that our framework detects errors with an average precision of {\~{}}94{\%} and an average recall of {\~{}}93{\%} across a diverse array of datasets that exhibit different types and amounts of errors. We compare our approach to a comprehensive collection of error detection methods, ranging from traditional rule-based methods to ensemble-based and active learning approaches. We show that data augmentation yields an average improvement of 20 F1 points while it requires access to 3× fewer labeled examples compared to other ML approaches.},
	archiveprefix = {arXiv},
	arxivid = {1904.02285},
	author = {Heidari, Alireza and McGrath, Joshua and Ilyas, Ihab F. and Rekatsinas, Theodoros},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	doi = {10.1145/3299869.3319888},
	eprint = {1904.02285},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Ovadia et al/2010/Ovadia et al. - 2010 - No Title.pdf:pdf},
	isbn = {9781450356435},
	issn = {07308078},
	journal = {Proc. ACM SIGMOD Int. Conf. Manag. Data},
	keywords = {Data Augmentation,Error Detection,Few-shot Learning,Machine Learning,Weak Supervision},
	mendeley-groups = {dataset shift,Rupali,mlsys,Zotero - library,Zotero - Zotero Library},
	pages = {829--846},
	publisher = {ACM},
	title = {{HoloDetect: Few-shot learning for error detection}},
	url = {https://doi.org/10.1145/3299869.3319888},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1145/3299869.3319888}}

@article{Rekatsinas,
	abstract = {We introduce HoloClean, a framework for holistic data repairing driven by probabilistic inference. HoloClean unifies existing qualitative data repairing approaches, which rely on integrity constraints or external data sources, with quantitative data repairing methods, which leverage statistical properties of the input data. Given an inconsistent dataset as input, HoloClean automatically generates a probabilistic program that performs data repairing. Inspired by recent theoretical advances in probabilistic inference, we introduce a series of optimizations which ensure that inference over HoloClean's probabilistic model scales to instances with millions of tuples. We show that HoloClean scales to instances with millions of tuples and find data repairs with an average precision of ∼ 90{\%} and an average recall of above ∼ 76{\%} across a diverse array of datasets exhibiting different types of errors. This yields an average F1 improvement of more than 2× against state-of-the-art methods.},
	author = {Rekatsinas, Theodoros and Chu, Xu and Ilyas, Ihab F. and R{\'{e}}, Christopher},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Ovadia et al/2010/Ovadia et al. - 2010 - No Title.pdf:pdf},
	issn = {23318422},
	journal = {arXiv},
	mendeley-groups = {Rupali,mlsys,Zotero - mendeley,Zotero - Zotero Library,Zotero - library},
	title = {{HoloClean: Holistic data repairs with probabilistic inference}},
	url = {http://www.vldb.org/pvldb/vol10/p1190-rekatsinas.pdf},
	year = {2017},
	Bdsk-Url-1 = {http://www.vldb.org/pvldb/vol10/p1190-rekatsinas.pdf}}

@article{Sculley2015,
	abstract = {Machine learning offers a fantastically powerful toolkit for building useful complex prediction systems quickly. This paper argues it is dangerous to think of these quick wins as coming for free. Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. We explore several ML-specific risk factors to account for in system design. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and a variety of system-level anti-patterns.},
	author = {Sculley, D. and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean Fran{\c{c}}ois and Dennison, Dan},
	date-added = {2021-04-02 17:20:24 +0200},
	date-modified = {2021-04-02 17:20:24 +0200},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Ovadia et al/2010/Ovadia et al. - 2010 - No Title.pdf:pdf},
	isbn = {0262017091, 9780262017091},
	issn = {10495258},
	journal = {Adv. Neural Inf. Process. Syst.},
	mendeley-groups = {Ml Advances,mlsys},
	pages = {2503--2511},
	title = {{Hidden technical debt in machine learning systems}},
	url = {http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf},
	volume = {2015-Janua},
	year = {2015},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf}}

@inproceedings{Schelter2020a,
	abstract = {Machine Learning (ML) models are difficult to maintain in production settings. In particular, deviations of the unseen serving data (for which we want to compute predictions) from the source data (on which the model was trained) pose a central challenge, especially when model training and prediction are outsourced via cloud services. Errors or shifts in the serving data can affect the predictive quality of a model, but are hard to detect for engineers operating ML deployments.We propose a simple approach to automate the validation of deployed ML models by estimating the model's predictive performance on unseen, unlabeled serving data. In contrast to existing work, we do not require explicit distributional assumptions on the dataset shift between the source and serving data. Instead, we rely on a programmatic specification of typical cases of dataset shift and data errors. We use this information to learn a performance predictor for a pretrained black box model that automatically raises alarms when it detects performance drops on unseen serving data.We experimentally evaluate our approach on various datasets, models and error types. We find that it reliably predicts the performance of black box models in the majority of cases, and outperforms several baselines even in the presence of unspecified data errors.},
	address = {New York, NY, USA},
	author = {Schelter, Sebastian and Rukat, Tammo and Biessmann, Felix},
	booktitle = {Proc. 2020 ACM SIGMOD Int. Conf. Manag. Data},
	date-added = {2021-03-23 22:27:31 +0100},
	date-modified = {2021-03-23 22:27:31 +0100},
	doi = {10.1145/3318464.3380604},
	isbn = {9781450367356},
	mendeley-groups = {Zotero - library,Zotero - Zotero Library},
	month = {jun},
	pages = {1289--1299},
	publisher = {ACM},
	title = {{Learning to Validate the Predictions of Black Box Classifiers on Unseen Data}},
	url = {https://dl.acm.org/doi/10.1145/3318464.3380604 https://ssc.io/pdf/blackbox-performance-prediction.pdf},
	year = {2020},
	Bdsk-Url-1 = {https://dl.acm.org/doi/10.1145/3318464.3380604%20https://ssc.io/pdf/blackbox-performance-prediction.pdf},
	Bdsk-Url-2 = {https://doi.org/10.1145/3318464.3380604}}

@inproceedings{Biessmann2018a,
	abstract = {The success of applications that process data critically depends on the quality of the ingested data. Completeness of a data source is essential in many cases. Yet, most missing value imputation approaches suffer from severe limitations. They are almost exclusively restricted to numerical data, and they either offer only simple imputation methods or are difficult to scale and maintain in production. Here we present a robust and scalable approach to imputation that extends to tables with non-numerical values, including unstructured text data in diverse languages. Experiments on public data sets as well as data sets sampled from a large product catalog in different languages (English and Japanese) demonstrate that the proposed approach is both scalable and yields more accurate imputations than previous approaches. Training on data sets with several million rows is a matter of minutes on a single machine. With a median imputation F1 score of 0.93 across a broad selection of data sets our approach achieves on average a 23-fold improvement compared to mode imputation. While our system allows users to apply state-of-the-art deep learning models if needed, we find that often simple linear n-gram models perform on par with deep learning methods at a much lower operational cost. The proposed method learns all parameters of the entire imputation pipeline automatically in an end-to-end fashion, rendering it attractive as a generic plugin both for engineers in charge of data pipelines where data completeness is relevant, as well as for practitioners without expertise in machine learning who need to impute missing values in tables with non-numerical data.},
	address = {New York, New York, USA},
	author = {Biessmann, Felix and Salinas, David and Schelter, Sebastian and Schmidt, Philipp and Lange, Dustin},
	booktitle = {Int. Conf. Inf. Knowl. Manag. Proc.},
	date-added = {2021-03-23 22:25:53 +0100},
	date-modified = {2021-03-23 22:25:53 +0100},
	doi = {10.1145/3269206.3272005},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Biessmann et al/2018/Biessmann et al. - 2018 - Deep learning for missing value imputation in tables with non-numerical data.pdf:pdf},
	isbn = {9781450360142},
	keywords = {data cleaning,missing value imputation},
	mendeley-groups = {mlsys},
	pages = {2017--2026},
	publisher = {ACM Press},
	title = {{Deep learning for missing value imputation in tables with non-numerical data}},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3272005},
	year = {2018},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?doid=3269206.3272005},
	Bdsk-Url-2 = {https://doi.org/10.1145/3269206.3272005}}

@inproceedings{GAIN,
	author = {Jinsung Yoon and James Jordon and Mihaela van der Schaar},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/icml/YoonJS18.bib},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning, {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15, 2018},
	editor = {Jennifer G. Dy and Andreas Krause},
	pages = {5675--5684},
	publisher = {{PMLR}},
	series = {Proceedings of Machine Learning Research},
	timestamp = {Wed, 03 Apr 2019 18:17:30 +0200},
	title = {{GAIN:} Missing Data Imputation using Generative Adversarial Nets},
	url = {http://proceedings.mlr.press/v80/yoon18a.html},
	volume = {80},
	year = {2018},
	Bdsk-Url-1 = {http://proceedings.mlr.press/v80/yoon18a.html}}

@book{Buuren,
	author = {Van Buuren, Stef},
	publisher = {CRC press},
	title = {TODO: Flexible imputation of missing data},
	year = {2018}}

@article{CaminoVAE,
	author = {R. Camino and Christian A. Hammerschmidt and R. State},
	journal = {ArXiv},
	title = {Improving Missing Data Imputation with Deep Generative Models},
	volume = {abs/1902.10666},
	year = {2019}}

@inproceedings{Jenga,
	author = {Sebastian Schelter and Tammo Rukat and Felix Biessmann},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/edbt/SchelterRB21.bib},
	booktitle = {Proceedings of the 24th International Conference on Extending Database Technology, {EDBT} 2021, Nicosia, Cyprus, March 23 - 26, 2021},
	doi = {10.5441/002/edbt.2021.63},
	editor = {Yannis Velegrakis and Demetris Zeinalipour{-}Yazti and Panos K. Chrysanthis and Francesco Guerra},
	pages = {529--534},
	publisher = {OpenProceedings.org},
	timestamp = {Sat, 20 Mar 2021 10:29:38 +0100},
	title = {{JENGA} - {A} Framework to Study the Impact of Data Errors on the Predictions of Machine Learning Models},
	url = {https://doi.org/10.5441/002/edbt.2021.63},
	year = {2021},
	Bdsk-Url-1 = {https://doi.org/10.5441/002/edbt.2021.63}}

@article{Imputation_Benchmark_1,
	archiveprefix = {arXiv},
	author = {Katarzyna Woznica and Przemyslaw Biecek},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-2007-02837.bib},
	eprint = {2007.02837},
	journal = {CoRR},
	timestamp = {Wed, 22 Jul 2020 12:09:15 +0200},
	title = {Does imputation matter? Benchmark for predictive models},
	url = {https://arxiv.org/abs/2007.02837},
	volume = {abs/2007.02837},
	year = {2020},
	Bdsk-Url-1 = {https://arxiv.org/abs/2007.02837}}

@article{Imputation_Benchmark_2,
	author = {Anil S. Jadhav and Dhanya Pramod and Krishnan Ramanathan},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/aai/JadhavPR19.bib},
	doi = {10.1080/08839514.2019.1637138},
	journal = {Appl. Artif. Intell.},
	number = {10},
	pages = {913--933},
	timestamp = {Mon, 26 Oct 2020 09:00:09 +0100},
	title = {Comparison of Performance of Data Imputation Methods for Numeric Dataset},
	url = {https://doi.org/10.1080/08839514.2019.1637138},
	volume = {33},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1080/08839514.2019.1637138}}

@article{Imputation_Benchmark_3,
	author = {Poulos, Jason and Valle, Rafael},
	journal = {Applied Artificial Intelligence},
	number = {2},
	pages = {186--196},
	publisher = {Taylor \& Francis},
	title = {Missing data imputation for supervised learning},
	volume = {32},
	year = {2018}}

@article{Imputation_Benchmark_4,
	author = {Dimitris Bertsimas and Colin Pawlowski and Ying Daisy Zhuo},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/jmlr/BertsimasPZ17.bib},
	journal = {J. Mach. Learn. Res.},
	pages = {196:1--196:39},
	timestamp = {Wed, 10 Jul 2019 15:28:37 +0200},
	title = {From Predictive Methods to Missing Data Imputation: An Optimization Approach},
	url = {http://jmlr.org/papers/v18/17-073.html},
	volume = {18},
	year = {2017},
	Bdsk-Url-1 = {http://jmlr.org/papers/v18/17-073.html}}

@article{Imputation_Benchmark_6,
	archiveprefix = {arXiv},
	author = {Hongbao Zhang and Pengtao Xie and Eric P. Xing},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1808-01684.bib},
	eprint = {1808.01684},
	journal = {CoRR},
	timestamp = {Sun, 02 Sep 2018 15:01:56 +0200},
	title = {Missing Value Imputation Based on Deep Generative Models},
	url = {http://arxiv.org/abs/1808.01684},
	volume = {abs/1808.01684},
	year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1808.01684}}

@inproceedings{AutoKeras,
	author = {Jin, Haifeng and Song, Qingquan and Hu, Xia},
	booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
	organization = {ACM},
	pages = {1946--1956},
	title = {Auto-Keras: An Efficient Neural Architecture Search System},
	year = {2019}}

@book{AutoML,
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/books/sp/HKV2019.bib},
	doi = {10.1007/978-3-030-05318-5},
	editor = {Frank Hutter and Lars Kotthoff and Joaquin Vanschoren},
	isbn = {978-3-030-05317-8},
	publisher = {Springer},
	series = {The Springer Series on Challenges in Machine Learning},
	timestamp = {Fri, 27 Mar 2020 08:32:01 +0100},
	title = {Automated Machine Learning - Methods, Systems, Challenges},
	url = {https://doi.org/10.1007/978-3-030-05318-5},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-030-05318-5}}

@inproceedings{VAE,
	author = {Diederik P. Kingma and Max Welling},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/KingmaW13.bib},
	booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
	editor = {Yoshua Bengio and Yann LeCun},
	timestamp = {Thu, 04 Apr 2019 13:20:07 +0200},
	title = {Auto-Encoding Variational Bayes},
	url = {http://arxiv.org/abs/1312.6114},
	year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1312.6114}}

@inproceedings{VIGAN,
	author = {Chao Shang and Aaron Palmer and Jiangwen Sun and Ko{-}Shin Chen and Jin Lu and Jinbo Bi},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/bigdataconf/ShangPSCLB17.bib},
	booktitle = {2017 {IEEE} International Conference on Big Data, BigData 2017, Boston, MA, USA, December 11-14, 2017},
	doi = {10.1109/BigData.2017.8257992},
	editor = {Jian{-}Yun Nie and Zoran Obradovic and Toyotaro Suzumura and Rumi Ghosh and Raghunath Nambiar and Chonggang Wang and Hui Zang and Ricardo Baeza{-}Yates and Xiaohua Hu and Jeremy Kepner and Alfredo Cuzzocrea and Jian Tang and Masashi Toyoda},
	pages = {766--775},
	publisher = {{IEEE} Computer Society},
	timestamp = {Sat, 30 May 2020 20:04:53 +0200},
	title = {{VIGAN:} Missing view imputation with generative adversarial networks},
	url = {https://doi.org/10.1109/BigData.2017.8257992},
	year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1109/BigData.2017.8257992}}

@inproceedings{MisGAN,
	author = {Steven Cheng{-}Xian Li and Bo Jiang and Benjamin M. Marlin},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/iclr/LiJM19.bib},
	booktitle = {7th International Conference on Learning Representations, {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019},
	publisher = {OpenReview.net},
	timestamp = {Thu, 25 Jul 2019 14:25:47 +0200},
	title = {MisGAN: Learning from Incomplete Data with Generative Adversarial Networks},
	url = {https://openreview.net/forum?id=S1lDV3RcKm},
	year = {2019},
	Bdsk-Url-1 = {https://openreview.net/forum?id=S1lDV3RcKm}}

@article{HIVAE,
	author = {Alfredo Naz{\'{a}}bal and Pablo M. Olmos and Zoubin Ghahramani and Isabel Valera},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/pr/NazabalOGV20.bib},
	doi = {10.1016/j.patcog.2020.107501},
	journal = {Pattern Recognit.},
	pages = {107501},
	timestamp = {Wed, 26 Aug 2020 11:04:13 +0200},
	title = {Handling incomplete heterogeneous data using VAEs},
	url = {https://doi.org/10.1016/j.patcog.2020.107501},
	volume = {107},
	year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.patcog.2020.107501}}

@article{VAE_for_genomic_data,
	abstract = {{As missing values are frequently present in genomic data, practical methods to handle missing data are necessary for downstream analyses that require complete data sets. State-of-the-art imputation techniques, including methods based on singular value decomposition and K-nearest neighbors, can be computationally expensive for large data sets and it is difficult to modify these algorithms to handle certain cases not missing at random.In this work, we use a deep-learning framework based on the variational auto-encoder (VAE) for genomic missing value imputation and demonstrate its effectiveness in transcriptome and methylome data analysis. We show that in the vast majority of our testing scenarios, VAE achieves similar or better performances than the most widely used imputation standards, while having a computational advantage at evaluation time. When dealing with data missing not at random (e.g., few values are missing), we develop simple yet effective methodologies to leverage the prior knowledge about missing data. Furthermore, we investigate the effect of varying latent space regularization strength in VAE on the imputation performances and, in this context, show why VAE has a better imputation capacity compared to a regular deterministic auto-encoder.We describe a deep learning imputation framework for transcriptome and methylome data using a VAE and show that it can be a preferable alternative to traditional methods for data imputation, especially in the setting of large-scale data and certain missing-not-at-random scenarios.}},
	author = {Qiu, Yeping Lina and Zheng, Hong and Gevaert, Olivier},
	doi = {10.1093/gigascience/giaa082},
	eprint = {https://academic.oup.com/gigascience/article-pdf/9/8/giaa082/33571399/giaa082.pdf},
	issn = {2047-217X},
	journal = {GigaScience},
	month = {08},
	note = {giaa082},
	number = {8},
	title = {{Genomic data imputation with variational auto-encoders}},
	url = {https://doi.org/10.1093/gigascience/giaa082},
	volume = {9},
	year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1093/gigascience/giaa082}}

@inproceedings{VAEM,
	author = {Chao Ma and Sebastian Tschiatschek and Richard E. Turner and Jos{\'{e}} Miguel Hern{\'{a}}ndez{-}Lobato and Cheng Zhang},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/nips/MaTTHZ20.bib},
	booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual},
	editor = {Hugo Larochelle and Marc'Aurelio Ranzato and Raia Hadsell and Maria{-}Florina Balcan and Hsuan{-}Tien Lin},
	timestamp = {Mon, 29 Mar 2021 13:34:46 +0200},
	title = {{VAEM:} a Deep Generative Model for Heterogeneous Mixed Type Data},
	url = {https://proceedings.neurips.cc/paper/2020/hash/8171ac2c5544a5cb54ac0f38bf477af4-Abstract.html},
	year = {2020},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2020/hash/8171ac2c5544a5cb54ac0f38bf477af4-Abstract.html}}

@inproceedings{GAN,
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger},
	publisher = {Curran Associates, Inc.},
	title = {Generative Adversarial Nets},
	url = {https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
	volume = {27},
	year = {2014},
	Bdsk-Url-1 = {https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf}}

@article{Graham,
	author = {Schafer, J. L. and Graham, J. W.},
	journal = {Psychol Methods},
	month = {Jun},
	number = {2},
	pages = {147--177},
	title = {{{M}issing data: our view of the state of the art}},
	volume = {7},
	year = {2002}}

@article{Rubin,
	author = {Donald B. Rubin},
	issn = {00063444},
	journal = {Biometrika},
	number = {3},
	pages = {581--592},
	publisher = {[Oxford University Press, Biometrika Trust]},
	title = {Inference and Missing Data},
	url = {http://www.jstor.org/stable/2335739},
	volume = {63},
	year = {1976},
	Bdsk-Url-1 = {http://www.jstor.org/stable/2335739}}

@book{Little,
	author = {Little, Roderick J. A. and Rubin, Donald B.},
	date-modified = {2021-04-02 21:10:37 +0200},
	isbn = {0471802549},
	publisher = {John Wiley \& Sons, Inc.},
	title = {Statistical Analysis with Missing Data. 2nd Edition},
	year = {2002}}
