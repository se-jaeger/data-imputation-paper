%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Felix Bie√ümann at 2021-03-23 22:43:04 +0100


%% Saved with string encoding Unicode (UTF-8)



@inproceedings{Schelter2020a,
	abstract = {Machine Learning (ML) models are difficult to maintain in production settings. In particular, deviations of the unseen serving data (for which we want to compute predictions) from the source data (on which the model was trained) pose a central challenge, especially when model training and prediction are outsourced via cloud services. Errors or shifts in the serving data can affect the predictive quality of a model, but are hard to detect for engineers operating ML deployments.We propose a simple approach to automate the validation of deployed ML models by estimating the model's predictive performance on unseen, unlabeled serving data. In contrast to existing work, we do not require explicit distributional assumptions on the dataset shift between the source and serving data. Instead, we rely on a programmatic specification of typical cases of dataset shift and data errors. We use this information to learn a performance predictor for a pretrained black box model that automatically raises alarms when it detects performance drops on unseen serving data.We experimentally evaluate our approach on various datasets, models and error types. We find that it reliably predicts the performance of black box models in the majority of cases, and outperforms several baselines even in the presence of unspecified data errors.},
	address = {New York, NY, USA},
	author = {Schelter, Sebastian and Rukat, Tammo and Biessmann, Felix},
	booktitle = {Proc. 2020 ACM SIGMOD Int. Conf. Manag. Data},
	date-added = {2021-03-23 22:27:31 +0100},
	date-modified = {2021-03-23 22:27:31 +0100},
	doi = {10.1145/3318464.3380604},
	isbn = {9781450367356},
	mendeley-groups = {Zotero - library,Zotero - Zotero Library},
	month = {jun},
	pages = {1289--1299},
	publisher = {ACM},
	title = {{Learning to Validate the Predictions of Black Box Classifiers on Unseen Data}},
	url = {https://dl.acm.org/doi/10.1145/3318464.3380604 https://ssc.io/pdf/blackbox-performance-prediction.pdf},
	year = {2020},
	Bdsk-Url-1 = {https://dl.acm.org/doi/10.1145/3318464.3380604%20https://ssc.io/pdf/blackbox-performance-prediction.pdf},
	Bdsk-Url-2 = {https://doi.org/10.1145/3318464.3380604}}

@inproceedings{Biessmann2018a,
	abstract = {The success of applications that process data critically depends on the quality of the ingested data. Completeness of a data source is essential in many cases. Yet, most missing value imputation approaches suffer from severe limitations. They are almost exclusively restricted to numerical data, and they either offer only simple imputation methods or are difficult to scale and maintain in production. Here we present a robust and scalable approach to imputation that extends to tables with non-numerical values, including unstructured text data in diverse languages. Experiments on public data sets as well as data sets sampled from a large product catalog in different languages (English and Japanese) demonstrate that the proposed approach is both scalable and yields more accurate imputations than previous approaches. Training on data sets with several million rows is a matter of minutes on a single machine. With a median imputation F1 score of 0.93 across a broad selection of data sets our approach achieves on average a 23-fold improvement compared to mode imputation. While our system allows users to apply state-of-the-art deep learning models if needed, we find that often simple linear n-gram models perform on par with deep learning methods at a much lower operational cost. The proposed method learns all parameters of the entire imputation pipeline automatically in an end-to-end fashion, rendering it attractive as a generic plugin both for engineers in charge of data pipelines where data completeness is relevant, as well as for practitioners without expertise in machine learning who need to impute missing values in tables with non-numerical data.},
	address = {New York, New York, USA},
	author = {Biessmann, Felix and Salinas, David and Schelter, Sebastian and Schmidt, Philipp and Lange, Dustin},
	booktitle = {Int. Conf. Inf. Knowl. Manag. Proc.},
	date-added = {2021-03-23 22:25:53 +0100},
	date-modified = {2021-03-23 22:25:53 +0100},
	doi = {10.1145/3269206.3272005},
	file = {:Users/felix/Dropbox/work/mendeley-literature/Biessmann et al/2018/Biessmann et al. - 2018 - Deep learning for missing value imputation in tables with non-numerical data.pdf:pdf},
	isbn = {9781450360142},
	keywords = {data cleaning,missing value imputation},
	mendeley-groups = {mlsys},
	pages = {2017--2026},
	publisher = {ACM Press},
	title = {{Deep learning for missing value imputation in tables with non-numerical data}},
	url = {http://dl.acm.org/citation.cfm?doid=3269206.3272005},
	year = {2018},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?doid=3269206.3272005},
	Bdsk-Url-2 = {https://doi.org/10.1145/3269206.3272005}}

@inproceedings{GAIN,
	author = {Jinsung Yoon and James Jordon and Mihaela van der Schaar},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/conf/icml/YoonJS18.bib},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning, {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15, 2018},
	editor = {Jennifer G. Dy and Andreas Krause},
	pages = {5675--5684},
	publisher = {{PMLR}},
	series = {Proceedings of Machine Learning Research},
	timestamp = {Wed, 03 Apr 2019 18:17:30 +0200},
	title = {{GAIN:} Missing Data Imputation using Generative Adversarial Nets},
	url = {http://proceedings.mlr.press/v80/yoon18a.html},
	volume = {80},
	year = {2018},
	Bdsk-Url-1 = {http://proceedings.mlr.press/v80/yoon18a.html}}

@book{Buuren,
	author = {Van Buuren, Stef},
	publisher = {CRC press},
	title = {TODO: Flexible imputation of missing data},
	year = {2018}}

@article{CaminoVAE,
	author = {R. Camino and Christian A. Hammerschmidt and R. State},
	journal = {ArXiv},
	title = {Improving Missing Data Imputation with Deep Generative Models},
	volume = {abs/1902.10666},
	year = {2019}}

@inproceedings{Jenga,
	author    = {Sebastian Schelter and
	Tammo Rukat and
	Felix Biessmann},
	editor    = {Yannis Velegrakis and
	Demetris Zeinalipour{-}Yazti and
	Panos K. Chrysanthis and
	Francesco Guerra},
	title     = {{JENGA} - {A} Framework to Study the Impact of Data Errors on the
	Predictions of Machine Learning Models},
	booktitle = {Proceedings of the 24th International Conference on Extending Database
	Technology, {EDBT} 2021, Nicosia, Cyprus, March 23 - 26, 2021},
	pages     = {529--534},
	publisher = {OpenProceedings.org},
	year      = {2021},
	url       = {https://doi.org/10.5441/002/edbt.2021.63},
	doi       = {10.5441/002/edbt.2021.63},
	timestamp = {Sat, 20 Mar 2021 10:29:38 +0100},
	biburl    = {https://dblp.org/rec/conf/edbt/SchelterRB21.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Imputation_Benchmark_1,
	archiveprefix = {arXiv},
	author = {Katarzyna Woznica and Przemyslaw Biecek},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-2007-02837.bib},
	eprint = {2007.02837},
	journal = {CoRR},
	timestamp = {Wed, 22 Jul 2020 12:09:15 +0200},
	title = {Does imputation matter? Benchmark for predictive models},
	url = {https://arxiv.org/abs/2007.02837},
	volume = {abs/2007.02837},
	year = {2020},
	Bdsk-Url-1 = {https://arxiv.org/abs/2007.02837}}

@article{Imputation_Benchmark_2,
	author = {Anil S. Jadhav and Dhanya Pramod and Krishnan Ramanathan},
	biburl = {https://dblp.org/rec/journals/aai/JadhavPR19.bib},
	doi = {10.1080/08839514.2019.1637138},
	journal = {Appl. Artif. Intell.},
	number = {10},
	pages = {913--933},
	timestamp = {Mon, 26 Oct 2020 09:00:09 +0100},
	biburl    = {https://dblp.org/rec/journals/aai/JadhavPR19.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},
@article{Imputation_Benchmark_3,
	title={Missing data imputation for supervised learning},
	author={Poulos, Jason and Valle, Rafael},
	journal={Applied Artificial Intelligence},
	volume={32},
	number={2},
	pages={186--196},
	year={2018},
	publisher={Taylor \& Francis}
},
@article{Imputation_Benchmark_4,
	author    = {Dimitris Bertsimas and
	Colin Pawlowski and
	Ying Daisy Zhuo},
	title     = {From Predictive Methods to Missing Data Imputation: An Optimization
	Approach},
	journal   = {J. Mach. Learn. Res.},
	volume    = {18},
	pages     = {196:1--196:39},
	year      = {2017},
	url       = {http://jmlr.org/papers/v18/17-073.html},
	timestamp = {Wed, 10 Jul 2019 15:28:37 +0200},
	biburl    = {https://dblp.org/rec/journals/jmlr/BertsimasPZ17.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},
@article{Imputation_Benchmark_6,
	author    = {Hongbao Zhang and
	Pengtao Xie and
	Eric P. Xing},
	title     = {Missing Value Imputation Based on Deep Generative Models},
	journal   = {CoRR},
	volume    = {abs/1808.01684},
	year      = {2018},
	url       = {http://arxiv.org/abs/1808.01684},
	archivePrefix = {arXiv},
	eprint    = {1808.01684},
	timestamp = {Sun, 02 Sep 2018 15:01:56 +0200},
	biburl    = {https://dblp.org/rec/journals/corr/abs-1808-01684.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
},
@inproceedings{AutoKeras,
	author = {Jin, Haifeng and Song, Qingquan and Hu, Xia},
	booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
	organization = {ACM},
	pages = {1946--1956},
	title = {Auto-Keras: An Efficient Neural Architecture Search System},
	year = {2019}}

@article{Generativ_survey,
	author = {Harshvardhan GM and Mahendra Kumar Gourisaria and Manjusha Pandey and Siddharth Swarup Rautaray},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/csr/GMGPR20.bib},
	doi = {10.1016/j.cosrev.2020.100285},
	journal = {Comput. Sci. Rev.},
	pages = {100285},
	timestamp = {Tue, 29 Dec 2020 18:23:11 +0100},
	title = {A comprehensive survey and analysis of generative models in machine learning},
	url = {https://doi.org/10.1016/j.cosrev.2020.100285},
	volume = {38},
	year = {2020},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.cosrev.2020.100285}}

@book{AutoML,
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/books/sp/HKV2019.bib},
	doi = {10.1007/978-3-030-05318-5},
	editor = {Frank Hutter and Lars Kotthoff and Joaquin Vanschoren},
	isbn = {978-3-030-05317-8},
	publisher = {Springer},
	series = {The Springer Series on Challenges in Machine Learning},
	timestamp = {Fri, 27 Mar 2020 08:32:01 +0100},
	title = {Automated Machine Learning - Methods, Systems, Challenges},
	url = {https://doi.org/10.1007/978-3-030-05318-5},
	year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-030-05318-5}}

@inproceedings{VAE,
  author    = {Diederik P. Kingma and
               Max Welling},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Auto-Encoding Variational Bayes},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014,
               Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year      = {2014},
  url       = {http://arxiv.org/abs/1312.6114},
  timestamp = {Thu, 04 Apr 2019 13:20:07 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaW13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
