%!TEX root = ../data-imputation.tex
\section{Related Work}
\label{sec:related_work}
%
Many studies present new or improved imputation methods \citep{Imputation_Benchmark_4, Imputation_Benchmark_6, GAIN, VAE_for_genomic_data, HIVAE, MisGAN, VIGAN} and several studies compare and benchmark imputation strategies \citep{Imputation_Benchmark_1, Imputation_Benchmark_2, Imputation_Benchmark_3}. Both have in common that they oftenÂ focus on specific aspects or use cases and do not aim at an extensive comparison. In contrast, our goal is to get a broad overview of the following dimensions:
%
\begin{enumerate}
	\item Number and heterogeneity of data sets
	\item Varying downstream tasks (binary classification, multi-class classification, and regression)
	\item Realistic missingness patterns and amount of missing values
	\item Imputation methods and optimized hyperparameters
	\item Evaluation on imputation accuracy and impact on downstream task performance
	\item Training on complete and incomplete data
\end{enumerate}

\cite{Imputation_Benchmark_3} compared the downstream task performance on two binary classification data sets ($N = 48,842$, and $N = 435$) with imputed and incomplete data. Therefore, they varied the amount of MCAR and MNAR values from $0\%$ to $40\%$ in categorical features. For the imputation, they used six models: mode, random, $k$-NN, logistic regression, random forest, and SVM. The authors optimize the hyperparameters for one of the three downstream tasks but not for the imputation models. They conclude that using a $k$-NN imputation model performs best in most situations.

Similarly, \cite{Imputation_Benchmark_2} compare seven imputation methods (random, median, $k$-NN, predictive mean matching, Bayesian linear regression, linear regression, and non-bayesian) without optimizing their hyperparameters based on five small and numeric data sets (max. $1030$ observations). The authors discuss different missingness patterns but do not state which one they used in their experiments. However, they measured the methods' imputation performance for $10\%$ to $50\%$ missing values. Again, the authors show that $k$-NN imputation is best independent from the data set and missingness fraction.

\cite{Imputation_Benchmark_1} evaluate and compare seven imputation methods (random, mean, softImpute, miss-Forest, VIM kknn, VIM hotdeck, and MICE) combined with five classification models regarding their predictive performance. Therefore,  they use $13$ binary classification data sets with missing values in at least one column, which is why they do not know the data's missingness pattern. The amount of missing values ranges between $1\%$ and about $33\%$. In contrast to \cite{Imputation_Benchmark_3, Imputation_Benchmark_2}, the authors can cope with the situation where only incomplete data is available for training. In their setting, they could not find a single best imputation method. However, they show that the combination of imputation method, downstream model, and metric ($F1$ or $AUC$) influences the results.

The following two papers differ from others because they aim to compare their proposed method against existing approaches. \cite{Imputation_Benchmark_6} implement an iterative expectation-maximization (EM) algorithm that learns and optimizes a latent representation of the data distribution, parameterized by a deep neural network, to perform the imputation. They use ten classification and three regression task data sets and 11 imputation baselines (zero, mean, median, MICE, miss-Forest, softImpute, $k$-NN, PCA, autoencoder, denoising autoencoder, residual autoencoder) for comparison. The authors conducted both evaluations, imputation and downstream task performance, with $25\%$, $50\%$, and $75\%$ MNAR missing values and showed that their method outperforms the baselines.

To the best of our knowledge \citep{Imputation_Benchmark_4} is the largest and most extensive comparison, although the authors focus on introducing an imputation algorithm and present its improvements. Their proposed algorithm cross-validates the choice of the best imputation method out of $k$-NN, SVM, or tree-based imputation methods, where the hyperparameters are cross-validated, too. The authors then benchmarked their approach on $84$ classification and regression tasks against five imputation methods: mean, predictive mean matching, Bayesian PCA, $k$-NN, and iterative $k$-NN. They measured the imputation and downstream task performance on $10\%$ to $50\%$ MCAR and MNAR missing values. The authors show that their proposed method outperforms the baselines, closely followed by $k$-NN and iterative $k$-NN.

We summarize the mentioned papers and related benchmarks in Table \ref{tab:related_work}. Most benchmarks use broad missingness fractions but lack realistic missingness conditions or a large number of heterogeneous data sets. Further, no paper systematically compares the imputation quality and impact on downstream tasks for imputation methods trained on complete and incomplete data. Studies presenting novel imputation methods based on deep learning often lack a comprehensive comparison with classical methods under realistic conditions, with few exceptions~\citep{Imputation_Benchmark_6}. In contrast, we aim at a broad and comprehensive benchmark, which accounts for all dimensions mentioned in this section.

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{multirow}
\begin{table}[]
	\centering
	\begin{tabular}{@{\extracolsep{4pt}}p{2cm}p{3cm}rp{1.5cm}p{1cm}llll@{}}
		\toprule
		\multicolumn{1}{c}{\multirow{2}{*}{Study}} & \multicolumn{1}{c}{\multirow{2}{*}{\# Data Sets/Tasks}} & \multicolumn{1}{c}{\multirow{2}{*}{\# B.}} & \multicolumn{2}{c}{Missingness}                             & \multicolumn{2}{c}{Evaluation}                       & \multicolumn{2}{c}{Training on}                         \\\cline{4-5} \cline{6-7}\cline{8-9}
		\\[-0.75em]
		\multicolumn{1}{c}{}                      & \multicolumn{1}{c}{}    & \multicolumn{1}{c}{}   & \multicolumn{1}{c}{Pattern} & \multicolumn{1}{c}{Fraction}                                    & \multicolumn{1}{c}{Imp.} & \multicolumn{1}{c}{Down.} & \multicolumn{1}{c}{Comp.} & \multicolumn{1}{c}{Incomp.} \\ \midrule
		\\[-.75em]
		\cite{Imputation_Benchmark_3}                                         & 2 binary clf.  & 6                                               & MCAR MAR                   & 0\% 10\% 20\% 30\% 40\%                                            & No                       & Yes                       & \multicolumn{2}{c}{\emph{unclear}}                             \\ \hline
		\\[-.75em]
		\cite{Imputation_Benchmark_2}                                         & 5 data sets      & 7                                          & \emph{unclear}                     & 10\% 20\% 30\% 40\% 50\%                                           & Yes                      & No                        & \multicolumn{2}{c}{\emph{unclear}}                         \\ \hline
		\\[-.75em]
		\cite{Imputation_Benchmark_1}                                         & 13 binary clf.    & 7                           & \emph{unclear*}                    & 1\% - $\sim$33\%                                                      & No                       & Yes                       & No                        & Yes                         \\\hline
		\\[-.75em]
		\cite{Imputation_Benchmark_6}                                         & 10 clf.\newline 3~~~regression     & 11                                  & MNAR                        & 25\% 50\% 75\%                                                       & Yes                      & Yes                       & \multicolumn{2}{c}{\emph{unclear}}                         \\\hline
		\\[-.75em]
		\citep{Imputation_Benchmark_4}                                         & 84 data sets\newline \footnotesize(clf. and regression)     & 5                                        & MCAR MNAR                  & 10\% 20\% 30\% 40\% 50\%                                           & Yes                      & Yes                       & \multicolumn{2}{c}{\emph{unclear}}                         \\\hline
		\\[-.75em]
		Ours                                      & 21 regression\newline 31 binary clf.\newline 17 multi-class clf.    & 6                 & MCAR MAR MNAR             & 1\% 10\% 30\% 50\%                                                  & Yes                      & Yes                       & Yes                       & Yes                         \\ \bottomrule
		\multicolumn{9}{l}{\footnotesize*Authors use incomplete datasets and, therefore, do not know the missingness pattern}
	\end{tabular}
	\caption{An overview of related benchmarks. In contrast to our benchmark, all other studies focus on specific aspects such as downstream tasks or missingness conditions. Most importantly, no paper systematically compares imputation methods trained on complete and incomplete data sets. Abbreviations: the symbol \emph{\#} stands for the number of, \emph{B.} means Baselines, \emph{Imp.} means Imputation Quality, \emph{Down.} means Impact on Downstream Task, \emph{Comp.} means Complete Data, \emph{Incomp.} means Incomplete Data, and \emph{clf.} means classification.}
	\label{tab:related_work}
\end{table}
