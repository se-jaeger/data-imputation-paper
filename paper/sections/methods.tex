%!TEX root = ../data-imputation.tex

\section{TODO: Methods}
%
One of the main goals of this work is to provide a comprehensive evaluation of missing value imputation methods under realistic conditions. In particular we focus on two aspects a) a large suite of real-world data sets and tasks and b) realistic missingness patterns. The following sections describe the data sets we considered as well as the missingness patterns, followed by a detailed description of the imputation methods compared.

\subsection{Datasets}
%
We focus on a broad evaluation with several numeric datasets and the most widespread tasks: regression, binary classification, and multi-class classification. The OpenML database\footnote{\url{https://www.openml.org/}} contains many thousand datasets that can directly be retrieved as \code{pandas DataFrames}\footnote{TODO Link + it is quasi standard..} that encode the columns' datatypes properly, which means categorical features are of \code{pandas dtype} \code{category}.

Especially deep learning models need sufficient data to learn their task properly. However, because we plan to run many experiments, the datasets must not be too big to keep training times feasible. This is why we choose datasets without missing values that contain 5 to 25 features and 3k to 100k observations. We then removed duplicated, corrupted, and Sparse ARFF\footnote{Attribute-Relation File Format} formatted datasets.

The resulting 69 datasets are composed of 21 regression, 31 binary classification, and 17 multi-class classification datasets. The supplementary material contains a detailed list of all datasets and further information, such as OpenML ID, name, and the number of observations and features.


\subsection{Missingness Patterns}
%
Most research on missing value imputation considers three different types of missingness patterns:
%
\begin{itemize}
\item Missing completely at random (MCAR): Values are discarded independent of any other values
\item Missing at random (MAR): Values in column $c$ are discarded dependent on values in another column $k\neq c$
\item Missing not at random (MNAR): Values in column $c$ are discarded dependent on their value in $c$
\end{itemize}
%
An example of the missingness patterns used is shown in \autoref{tab:missingness_patterns}. \sebastian{Mabye add a sixth row in the table. 50\% missigness in 5 rows is a bit confusing.}
%
\begin{table}
	\centering
	\caption{
		Examples of missingness patterns for a toy data set with a numerical column A and a categorical column B and a missingness ratio of 50\%. Applying the MCAR condition to column B discards two values independent of the values in A or B. In the MAR condition values in B are discarded on their corresponding values in column A; discarded values in B here correspond to values in A in the range between $[0.4,0.6]$. In the MNAR condition applied to column B we discard values based on their value in B; here we see that only values \textit{b} were discarded, not values \textit{a}.
	}
	\label{tab:missingness_patterns}
	\vspace{1em}
	\begin{tabular}{rcccc}
		\toprule
		 A & B & B$_{\text{MCAR}}$ & B$_{\text{MAR}}$ & B$_{\text{MNAR}}$ \\
		\midrule
		0.0 & b &      ? &     b &      ? \\
		0.2 & b &      b &     b &      ? \\
		0.4 & b &      ? &     ? &      b \\
		0.6 & a &      a &     ? &      a \\
		0.8 & a &      a &     a &      a \\
		\bottomrule
	\end{tabular}
\end{table}


\subsection{Imputation Methods}
%
In this section, we describe our six single imputation methods. The overall goal of an imputer is to train a model on $X = [X_1, X_2, ..., X_{i-1}, X_{i+1}, ..., X_n]$, where $n$ is the number of features and $X_i$ the to-be-imputed column. To abstract crucial steps, such as encode, normalize, and decode the data and cross-validate the imputer's hyperparameters, we define a common framework inspired by \emph{scikit-learn}\footnote{TODO Link}.

TODO: irgendwo muss hin, dass wir mit means auff√ºllen, wenn zur trinings time missing values auftauchen...


\subsubsection{Simple Imputer}
%
Our \code{Simple Imputer} uses the column-wise \code{mean} for numerical or \code{mode}, i.e., the most frequent value,  for categorical columns to fill missing values.


\subsubsection{Machine Learning Imputer}
%
We use two common imputation methods as representatives: \emph{K-NN Imputer} and \emph{Random Forest Imputer}. Both encode categorical features as one-hot columns and normalize the data by rescaling it to zero mean and unit variance. The imputer's hyperparameters are optimized by 5-fold cross-validated grid-search.

For our K-NN Imputer, we use, depending on the target columns' datatype (categorical or numerical), \code{scikit-learn}'s \code{KNeighborsClassifier} or \code{KNeighborsRegressor} and optimizes the $n\_neighbors \in \{1, 3, 5\}$  hyperparameter.

Similarly, the Random Forest Imputer uses the \code{RandomForestClassifier} or \code{RandomForestRegressor} and optimizes the hyperparameter $n\_estimators \in \{10, 50, 100\}$.


\subsubsection{Deep Learning Imputer}
%
Already very simple deep learning models can achieve good imputation results (TODO: cite). To easily optimize the model's architecture, we use the AutoML\footnote{"automated machine learning (AutoML) [...] automatically set [the model's] hyperparameters to optimize performance" \cite{AutoML}} library \code{autokeras} \cite{AutoKeras} to build our \emph{Deep Learning Imputer}.

For categorical columns, we use AutoKeras' \code{StructuredDataClassifier} and for numerical columns \code{StructuredDataRegressor}. Both classes take care of properly encode the data and optimize the model's architecture and hyperparameters. To reduce the training time, we change the maximum number of trials to $50$, which means \code{autokeras} tries 50 different model architecture and hyperparameter combinations, and the maximal number or of $epochs$ (\code{autokeras} uses early stopping) to 50.


\subsubsection{Generative Imputer}
%
Several generative models are successfully applied to data imputation, especially variational autoencoders (VAE) (TODO: cites), and generative adversarial networks (GAN) (TODO: cites). Autoencoders in general, learn to encode their input into an latent representation and, at the same time, to decode this latent representation back into the original feature space. In contrast to this, VAEs learn to decode their input into a distribution over the latent space and decode a sample from this distribution, which makes them generative.



\subsection{Evaluation Dimensions}
%

Was wir messen:
Imputation Accuracy und Downstream Performance

Imputation Accuracy, depending on column data type:
categorical: F1 (TODO: macro/avg?)
numerical: RMSE (TODO`?)

Downstream Performance, depending on data type:
Classification: F1(TODO: macro/avg?)
numerical: RMSE (TODO?)
